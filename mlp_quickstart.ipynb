{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgwToU_ZZ7uy"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDP5WXKyNf82",
        "outputId": "2c740b14-ff5e-4422-8b2c-38baaf9ea2b6"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/XavierSpycy/NumPyMultilayerPerceptron.git\n",
        "%cd NumPyMultilayerPerceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXVF4F7daFF1"
      },
      "source": [
        "## Toy Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfKgwtzDbFqL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nn.mlp import MultilayerPerceptron\n",
        "from nn.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "IvAeN5yxZ5q7",
        "outputId": "57471a17-e1cf-40ee-87d4-28bb603a705a"
      },
      "outputs": [],
      "source": [
        "np.random.seed(3407)\n",
        "class_1 = np.hstack([np.random.normal( 1, 1, size=(500, 2)),  np.ones(shape=(500, 1))])\n",
        "class_2 = np.hstack([np.random.normal(-1, 1, size=(200, 2)), -np.ones(shape=(200, 1))])\n",
        "dataset = np.vstack([class_1, class_2])\n",
        "X, y = dataset[:,:2], dataset[:,2]\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(class_1[:,0], class_1[:,1], label='1')\n",
        "plt.scatter(class_2[:,0], class_2[:,1], label='-1')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "LxlIdT0aaP5v",
        "outputId": "5c5f65bc-bbbc-4790-d04c-3f0782b3f738"
      },
      "outputs": [],
      "source": [
        "layers = [\n",
        "    Dense(2, 4, activation='leaky_relu', init='kaiming_normal', init_params={'mode': 'out'}),\n",
        "    Dense(4, 3, activation='hardswish', init='xavier_normal'),\n",
        "    Dense(3, 2, activation='relu', init='kaiming_normal', init_params={'mode': 'in'}),\n",
        "    Dense(2, 1, activation='tanh', init='xavier_uniform')\n",
        "]\n",
        "mlp = MultilayerPerceptron(layers)\n",
        "mlp.compile(optimizer='Adam',\n",
        "            loss='MeanSquareError')\n",
        "mlp.fit(X, y, epochs=80, batch_size=8, use_progress_bar=True)\n",
        "mlp.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "Hl819GioaZ9-",
        "outputId": "3529e6be-0827-4db0-96a4-0344b52ee01f"
      },
      "outputs": [],
      "source": [
        "xx, yy = np.meshgrid(np.arange(-2, 2, .02),np.arange(-2, 2, .02))\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.pcolormesh(xx, yy, Z>0, cmap='cool')\n",
        "plt.scatter(X[:,0], X[:,1], c=[['b', 'r'][int(d>0)] for d in y], s=100)\n",
        "plt.xlim(-2, 2)\n",
        "plt.ylim(-2, 2)\n",
        "plt.grid()\n",
        "plt.title('Targets')\n",
        "plt.subplot(1,2,2)\n",
        "plt.pcolormesh(xx, yy, Z>0, cmap='cool')\n",
        "plt.scatter(X[:,0], X[:,1], c=[['b', 'r'][int(d>0)] for d in mlp.predict(X)], s=100)\n",
        "plt.xlim(-2, 2)\n",
        "plt.ylim(-2, 2)\n",
        "plt.grid()\n",
        "plt.title('Predictions')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CtPymdDZ63Q"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "x53e1Y0kN1tG",
        "outputId": "f5243ac7-734f-474d-9c41-680c5b74361d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets.data_loader import datasets\n",
        "from nn.mlp import MultilayerPerceptron\n",
        "from nn.layers import Dense, Dropout\n",
        "from nn.optim import Adam\n",
        "from nn.schedules import MultiStepLR\n",
        "from sklearn.metrics import accuracy_score as accuracy\n",
        "\n",
        "X_train, y_train = datasets(train=True)\n",
        "X_test, y_test = datasets(train=False)\n",
        "\n",
        "np.random.seed(3407)\n",
        "\n",
        "layers = [\n",
        "    Dense(128, 120, activation='elu', init='kaiming_uniform'),\n",
        "    Dropout(dropout_rate=0.25),\n",
        "    Dense(120, 112, activation='elu', init='kaiming_uniform'),\n",
        "    Dropout(dropout_rate=0.20),\n",
        "    Dense(112, 96, activation='elu', init='kaiming_uniform'),\n",
        "    Dropout(dropout_rate=0.15),\n",
        "    Dense(96, 64, activation='elu', init='kaiming_uniform'),\n",
        "    Dropout(dropout_rate=0.10),\n",
        "    Dense(64, 48, activation='elu', init='kaiming_uniform'),\n",
        "    Dropout(dropout_rate=0.05),\n",
        "    Dense(48, 32, activation='elu', init='kaiming_uniform'),\n",
        "    Dense(32, 24, activation='elu', init='kaiming_uniform'),\n",
        "    Dense(24, 16, activation='elu', init='kaiming_uniform'),\n",
        "    Dense(16, 10, activation='softmax', init='xavier_uniform')\n",
        "]\n",
        "\n",
        "mlp = MultilayerPerceptron(layers)\n",
        "optimizer = Adam(lr=1e-3, weight_decay=0.02)\n",
        "scheduler = MultiStepLR(optimizer, milestones=[100, 200, 300, 400], gamma=0.8)\n",
        "mlp.compile(optimizer=optimizer,\n",
        "            loss='CrossEntropy',\n",
        "            scheduler=scheduler)\n",
        "mlp.fit(X_train, y_train, epochs=500, batch_size=32, use_progress_bar=True)\n",
        "loss = mlp.loss_tracker()\n",
        "train_time = mlp.training_time()\n",
        "print(f'Training time: {train_time:.2f} second(s).')\n",
        "print(f'Loss: {loss[-1]:.2f}.')\n",
        "\n",
        "print(f\"Accuracy on the training set is: {accuracy(y_train, mlp.predict(X_train)):.2%}.\" )\n",
        "print(f\"Accuracy on the test set is: {accuracy(y_test, mlp.predict(X_test)):.2%}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Colab Built-in Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification task\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nn.layers import Dense\n",
        "from nn.optim import Adam\n",
        "from nn.mlp import MultilayerPerceptron\n",
        "from sklearn.metrics import accuracy_score as accuracy\n",
        "data_train = pd.read_csv('/content/sample_data/mnist_train_small.csv', header=None).to_numpy()\n",
        "data_test = pd.read_csv('/content/sample_data/mnist_test.csv', header=None).to_numpy()\n",
        "\n",
        "X_train, y_train = data_train[:,1:], data_train[:,0]\n",
        "X_test, y_test = data_test[:,1:], data_test[:,0]\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "np.random.seed(3407)\n",
        "\n",
        "layers = [\n",
        "    Dense(784, 128, activation='relu', init='kaiming_uniform'),\n",
        "    Dense(128, 16, activation='relu', init='kaiming_uniform'),\n",
        "    Dense(16, 10, activation='softmax')\n",
        "]\n",
        "\n",
        "mlp = MultilayerPerceptron(layers)\n",
        "mlp.compile(optimizer=Adam(),\n",
        "            loss='CrossEntropy')\n",
        "mlp.fit(X_train, y_train, epochs=10, batch_size=32, use_progress_bar=True)\n",
        "loss = mlp.loss_tracker()\n",
        "train_time = mlp.training_time()\n",
        "print(f'Training time: {train_time:.2f} second(s).')\n",
        "print(f'Loss: {loss[-1]:.2f}.')\n",
        "mlp.plot_loss()\n",
        "\n",
        "print(f\"Accuracy on the training set is: {accuracy(y_train, mlp.predict(X_train)):.2%}.\" )\n",
        "print(f\"Accuracy on the test set is: {accuracy(y_test, mlp.predict(X_test)):.2%}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Regression task\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nn.layers import Dense\n",
        "from nn.optim import Adam\n",
        "from nn.mlp import MultilayerPerceptron\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "data_train = pd.read_csv('/content/sample_data/california_housing_train.csv').to_numpy()\n",
        "data_test = pd.read_csv('/content/sample_data/california_housing_test.csv').to_numpy()\n",
        "X_train, y_train = data_train[:, :-1], data_train[:, -1]\n",
        "X_test, y_test = data_test[:, :-1], data_test[:, -1]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "np.random.seed(3407)\n",
        "\n",
        "layers = [\n",
        "    Dense(8, 6, activation='relu', init='kaiming_uniform'),\n",
        "    Dense(6, 4, activation='relu', init='kaiming_uniform'),\n",
        "    Dense(4, 2, activation='relu', init='kaiming_uniform'),\n",
        "    Dense(2, 1)\n",
        "]\n",
        "\n",
        "mlp = MultilayerPerceptron(layers)\n",
        "mlp.compile(optimizer=Adam(),\n",
        "            loss='MeanSquareError')\n",
        "\n",
        "mlp.fit(X_train, y_train, epochs=500, batch_size=32, use_progress_bar=True)\n",
        "train_time = mlp.training_time()\n",
        "print(f'Training time: {train_time:.2f} second(s).')\n",
        "mlp.plot_loss()\n",
        "\n",
        "print(f\"R^2 on the training set is: {r2_score(y_train, mlp.predict(X_train)):.2%}\")\n",
        "print(f\"R^2 on the test set is: {r2_score(y_test, mlp.predict(X_test)):.2%}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
